{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo automl - Wine Reviews**"
      ],
      "metadata": {
        "id": "Y6HUILI_SRQi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4dA2moJR9et"
      },
      "outputs": [],
      "source": [
        "# Instalando pacotes\n",
        "!pip install pycaret\n",
        "!pip install umap-learn\n",
        "!pip install --upgrade nbformat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Baixando modelo pré-treinado\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "id": "BxCwjbB6ShLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Biblioteca AutoML Pycaret\n",
        "from pycaret.classification import *\n",
        "\n",
        "# Parâmetros de configuração dos gráficos\n",
        "from matplotlib import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 4\n",
        "rcParams['lines.linewidth'] = 3\n",
        "rcParams['xtick.labelsize'] = 'x-large'\n",
        "rcParams['ytick.labelsize'] = 'x-large'\n",
        "\n",
        "# Versão da Linguagem Python\n",
        "from platform import python_version\n",
        "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())\n",
        "\n",
        "# Versões dos pacotes usados neste jupyter notebook\n",
        "#%reload_ext watermark\n",
        "#%watermark -a \"Verções bibliotecas\" --iversions\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from pycaret.utils import enable_colab\n",
        "enable_colab()"
      ],
      "metadata": {
        "id": "FgyApcHZShQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Base dados**"
      ],
      "metadata": {
        "id": "3P1GXDg1Srx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/winemag-data-130k-v2.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "X9Jzxu3kShUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando os 5 primeiros dados\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "QaDdjrouShbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando os 5 últimos dados\n",
        "data.tail(5)"
      ],
      "metadata": {
        "id": "ZAEuvyI4S6jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando linhas e colunas\n",
        "data.shape"
      ],
      "metadata": {
        "id": "3eNqYctTS6nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informações dos dados\n",
        "data.info()"
      ],
      "metadata": {
        "id": "nU0DJ-TgS6qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tipo dados\n",
        "data.dtypes"
      ],
      "metadata": {
        "id": "F-UcDeWkS6s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colunas númericas\n",
        "nub = [\"points\", \n",
        "       \"price\"]\n",
        "\n",
        "# Coluna categorica\n",
        "cat = [\"country\", \n",
        "       \"designation\", \n",
        "       \"province\", \n",
        "       \"region_1\",\n",
        "       \"region_2\",\n",
        "       \"taster_name\",\n",
        "       \"taster_twitter_handle\",\n",
        "       \"title\",\n",
        "       \"variety\",\n",
        "       \"winery\"]\n",
        "\n",
        "# Coluna target\n",
        "target = [\"description\"]"
      ],
      "metadata": {
        "id": "9GrMJByuShe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['description'] = data['description'].astype(str)\n",
        "data['title'] = data['title'].astype(str)"
      ],
      "metadata": {
        "id": "FJKZu2_PShi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total description\n",
        "data[\"description\"].value_counts()"
      ],
      "metadata": {
        "id": "yKGrtFj7TCU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumo variáveis numéricas\n",
        "data[nub].describe()"
      ],
      "metadata": {
        "id": "O05aT-QIT_oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listando o total por categoria de cada variável categórica\n",
        "for col in cat:\n",
        "    print(f'''Total de Registros Por Categoria da Variável {col}:''')\n",
        "    print(data[col].value_counts())\n",
        "    print()"
      ],
      "metadata": {
        "id": "f3L0Z_cIT_rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = nub\n",
        "for i in range(0, len(features)):\n",
        "    plt.subplot(1, len(features), i + 1)\n",
        "    sns.boxplot(y = data[features[i]], color = 'blue', orient = 'v')\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "zN9dPo4FT_uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(nub)):\n",
        "    plt.subplot(1, len(nub), i+1)\n",
        "    sns.violinplot(y = data[nub[i]], color = 'yellow', orient = 'v')\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "0TIbyVBJT_xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize= (18, 8))\n",
        "sns.histplot(data[\"price\"])"
      ],
      "metadata": {
        "id": "G4U7IqxzT_0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "todos_palavras = ' '.join([texto for texto in data[\"description\"]])\n",
        "nuvem_palavras = WordCloud(width = 800, \n",
        "                           height = 500, \n",
        "                           max_font_size = 110,\n",
        "                           collocations = False).generate(todos_palavras)\n",
        "\n",
        "plt.figure(figsize= (25.5, 17))\n",
        "plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oIp4K5QNTCYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "todos_palavras = ' '.join([texto for texto in data[\"title\"]])\n",
        "nuvem_palavras = WordCloud(width = 800, \n",
        "                           height = 500, \n",
        "                           max_font_size = 110,\n",
        "                           collocations = False).generate(todos_palavras)\n",
        "\n",
        "plt.figure(figsize= (25.5, 17))\n",
        "plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wlvtzdPKTCbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-processamento**"
      ],
      "metadata": {
        "id": "2S_sS-y1T4Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas sistema\n",
        "import re\n",
        "import unicodedata\n",
        "import itertools\n",
        "\n",
        "# Importando NLTK NLP\n",
        "# Baixando pacote do nltk\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Baixando todos os complementos NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "5zUJsvtQT2xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Dados de limpeza para modelo PLN\n",
        "# Variável para treino\n",
        "x = data[\"description\"]\n",
        "\n",
        "# Lista de stopwords\n",
        "list_stop_words = ['covfefe']\n",
        "\n",
        "# Recebe uma lista de palavras ou texto como entrada e retorna um conjunto de palavras mais limpo. \n",
        "# A função faz normalização, codificação/decodificação, letras minúsculas e lematização.\n",
        "def limpeza(texto):\n",
        "    WNL = nltk.stem.WordNetLemmatizer()\n",
        "    stop_words2 = nltk.corpus.stopwords.words(\"english\") + stopwords\n",
        "    texto = (unicodedata.normalize(\"NFKD\", texto).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\").lower())\n",
        "    WORDS = re.sub(r'[^\\w\\s]', '', texto).split()\n",
        "    return [WNL.lemmatize(word) for word in WORDS if word not in stop_words2]\n",
        "\n",
        "# Remove stop words: Removendo as stop words na base de dados\n",
        "def remove_stop_words(instancia): # Removendo as stop words\n",
        "    stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
        "    return (\" \".join(palavras))\n",
        "\n",
        "# Palavras derivacionalmente relacionadas com significados semelhantes, palavras para retornar documentos que contenham outra palavra no conjunto.\n",
        "def text_stemming(instancia):\n",
        "    stemmer = nltk.stem.RSLPStemmer()\n",
        "    palavras = []\n",
        "    for w in instancia.split():\n",
        "        palavras.append(stemmer.stem(w))\n",
        "        return (\" \".join(palavras))\n",
        "\n",
        "# Limpeza na base de dados limpando dados de web com http e outros.\n",
        "def dados_limpos(instancia): \n",
        "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
        "    return (instancia)\n",
        "\n",
        "#Lemmatization: Em linguística é o processo de agrupar as formas flexionadas de uma palavra para que possam ser analisadas como um único item, identificado pelo lema da palavra , ou forma de dicionário.\n",
        "def Lemmatization(instancia):\n",
        "    palavras = []\n",
        "    for w in instancia.split():\n",
        "        palavras.append(wordnet_lemmatizer.lemmatize(w))\n",
        "        return (\" \".join(palavras))\n",
        "\n",
        "# Preprocessing: Pré - processamento da base de dados que serão ser para análise de dados.\n",
        "def Preprocessing(instancia):\n",
        "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','')\n",
        "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
        "    return (\" \".join(palavras))\n",
        "\n",
        "# remover caracteres alphanuméricos\n",
        "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', '', x)\n",
        "\n",
        "# remover pontuações\n",
        "punc = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
        "\n",
        "# remover espaços duplos\n",
        "remove_space = lambda x: x.replace('  ', ' ')\n",
        "\n",
        "# Removendo pontuações descrições itens com expressão regular\n",
        "data['description'] = data['description'].str.replace('[,.:;!?]+', ' ', regex=True).copy()\n",
        "\n",
        "# Removendo os caracteres especiais de descrições \n",
        "data['description'] = data['description'].str.replace ('[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', regex=True).copy()\n",
        "\n",
        "# Removendo palavras com números \n",
        "data['description'] = data['description'].str.replace('[0-9]+', '', regex=True).copy()\n",
        "\n",
        "# Gerando a base dados limpo\n",
        "x = [Preprocessing(i) for i in x]\n",
        "\n",
        "# Aplicando nova coluna\n",
        "data[\"text_clean\"] = data[\"description\"].apply(Preprocessing)\n",
        "\n",
        "# Mundando os tipo de dados de object para string \n",
        "data[\"text_clean\"] = data[\"text_clean\"].astype(str)\n",
        "\n",
        "# Salvando base textos\n",
        "# Salvando arquivo em csv\n",
        "data.to_csv(\"text_clean.csv\", index=False)\n",
        "\n",
        "# Salvando arquivo em text\n",
        "data.to_csv(\"text_clean.text\", index=False)"
      ],
      "metadata": {
        "id": "7JHJTlz_T20V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando coluna texto\n",
        "data.text_clean.head(15)"
      ],
      "metadata": {
        "id": "2EydAmT5VIH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nuvem de palavras coluna texto limpo\n",
        "todos_palavras = ' '.join([texto for texto in data[\"text_clean\"]])\n",
        "nuvem_palavras = WordCloud(width = 800, \n",
        "                           height = 500, \n",
        "                           max_font_size = 110,\n",
        "                           collocations = False).generate(todos_palavras)\n",
        "\n",
        "plt.figure(figsize= (25.5, 17))\n",
        "plt.title(\"Nuvem de palavras limpas\")\n",
        "plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Fnp322bT23R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo nlp - Pré treinado spacy**"
      ],
      "metadata": {
        "id": "3bKoAzP2VXYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "XOzlmEW1T27y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo NLP - AutoML**"
      ],
      "metadata": {
        "id": "Q4ISurfbVbFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.nlp import *\n",
        "\n",
        "model = setup(data = data, \n",
        "                   target = 'text_clean', \n",
        "                   session_id = 123)"
      ],
      "metadata": {
        "id": "uRpP9nLUT2-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda = create_model('lda')\n",
        "print(lda)"
      ],
      "metadata": {
        "id": "udTUqvzBVgQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda2 = create_model('lda', \n",
        "                    num_topics = 10, \n",
        "                    multi_core = True)\n",
        "print(lda2)"
      ],
      "metadata": {
        "id": "1weewAnvVgTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_results = assign_model(lda)\n",
        "lda_results.head()"
      ],
      "metadata": {
        "id": "qidoff4kVgWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_results.to_csv(\"results.csv\")"
      ],
      "metadata": {
        "id": "Vr7Hb8VfYPN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model()"
      ],
      "metadata": {
        "id": "NnKhRBSxVgYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'frequency')"
      ],
      "metadata": {
        "id": "CfRc6QvyVngC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'topic_distribution')"
      ],
      "metadata": {
        "id": "FYHB4CZVVnjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'topic_model')"
      ],
      "metadata": {
        "id": "RhU9PUC7VnmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(plot = 'bigram')"
      ],
      "metadata": {
        "id": "h8hT-CnZVnpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'frequency', topic_num = 'Topic 1')"
      ],
      "metadata": {
        "id": "tEhGDRJCVntV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'frequency', topic_num = 'Topic 2')"
      ],
      "metadata": {
        "id": "GhZBYF5BVnx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'topic_distribution')"
      ],
      "metadata": {
        "id": "PRD7VwImVgbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(lda)"
      ],
      "metadata": {
        "id": "7Csd-zxUVgd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo 2 Automl**"
      ],
      "metadata": {
        "id": "EuP9IM6VVxLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = ['co','http','go','get']\n",
        "setup(data, \n",
        "      target = 'description',\n",
        "      session_id = 123, \n",
        "      custom_stopwords = stopwords)"
      ],
      "metadata": {
        "id": "ays6OziSVu6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda2 = create_model('lda')"
      ],
      "metadata": {
        "id": "FkJjtbyyVu9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda2, plot = 'topic_distribution')"
      ],
      "metadata": {
        "id": "PNCRlCKCVvA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = assign_model(lda2)\n",
        "df2"
      ],
      "metadata": {
        "id": "GXwxVxnFV8Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tune model**"
      ],
      "metadata": {
        "id": "sBwQJdc_WYdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp_nlp102 = setup(data = data, \n",
        "                   target = 'text_clean', \n",
        "                   session_id = 123,\n",
        "                   custom_stopwords = ['loan', 'income', 'usd', 'many', 'also', 'make', 'business', 'buy', \n",
        "                                       'sell', 'purchase','year', 'people', 'able', 'enable', 'old', 'woman',\n",
        "                                       'child', 'school'],\n",
        "                   log_experiment = True)"
      ],
      "metadata": {
        "id": "Fw8E4tZZV8Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda = create_model('lda')\n",
        "lda"
      ],
      "metadata": {
        "id": "QxxqUFBUV8UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'topic_distribution')"
      ],
      "metadata": {
        "id": "c6tBU7EcV8Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_unsupervised = tune_model(model = 'lda', multi_core = True)\n",
        "tuned_unsupervised"
      ],
      "metadata": {
        "id": "W2-QRk3OV8Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(lda,'Final LDA Model 08Feb2020')"
      ],
      "metadata": {
        "id": "Xei-z40iV8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_lda = load_model('Final LDA Model 08Feb2020')\n",
        "print(saved_lda)"
      ],
      "metadata": {
        "id": "HuEygzvpWVPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6yrfrea-WVTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}