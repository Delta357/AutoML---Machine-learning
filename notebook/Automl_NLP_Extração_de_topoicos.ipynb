{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AutoML - Extração topicos**"
      ],
      "metadata": {
        "id": "Yt0UOFgQB0-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwGwju20BYk8"
      },
      "outputs": [],
      "source": [
        "# Instalando pacotes\n",
        "!pip install pycaret\n",
        "!pip install umap-learn\n",
        "!pip install --upgrade nbformat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando modelo pré-treinado\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "id": "ss2YSyhcB5J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Biblioteca AutoML Pycaret\n",
        "from pycaret.classification import *\n",
        "\n",
        "# Parâmetros de configuração dos gráficos\n",
        "from matplotlib import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 4\n",
        "rcParams['lines.linewidth'] = 3\n",
        "rcParams['xtick.labelsize'] = 'x-large'\n",
        "rcParams['ytick.labelsize'] = 'x-large'\n",
        "\n",
        "# Versão da Linguagem Python\n",
        "from platform import python_version\n",
        "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())\n",
        "\n",
        "# Versões dos pacotes usados neste jupyter notebook\n",
        "#%reload_ext watermark\n",
        "#%watermark -a \"Verções bibliotecas\" --iversions\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from pycaret.utils import enable_colab\n",
        "enable_colab()"
      ],
      "metadata": {
        "id": "q3DnJNCPB5OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/Delta357/AutoML---Machine-learning/main/data/MachineLearning_reddit.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "76HdqQyBB5RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the shape of data\n",
        "data.shape"
      ],
      "metadata": {
        "id": "kI1km8HYCTmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "2jk7jczyCTqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.nlp import *\n",
        "\n",
        "exp_nlp101 = setup(data = data, \n",
        "                   target = 'title', \n",
        "                   session_id = 123)"
      ],
      "metadata": {
        "id": "5FjqBv47CTuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda = create_model('lda')\n",
        "print(lda)"
      ],
      "metadata": {
        "id": "lGQ1efYTCcaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda2 = create_model('lda', \n",
        "                    num_topics = 10, \n",
        "                    multi_core = True)\n",
        "print(lda2)"
      ],
      "metadata": {
        "id": "7dDjm9WCCced"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_results = assign_model(lda)\n",
        "lda_results.head()"
      ],
      "metadata": {
        "id": "iLzXVQ7bCch8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model()"
      ],
      "metadata": {
        "id": "StMaFQZ6Ccls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'frequency')"
      ],
      "metadata": {
        "id": "9kPsnt04Cco6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'topic_distribution')"
      ],
      "metadata": {
        "id": "bYkCrzCYCcsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'topic_model')"
      ],
      "metadata": {
        "id": "Aup5smLOCcvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(plot = 'bigram')"
      ],
      "metadata": {
        "id": "FXeLphuhCcy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'frequency', topic_num = 'Topic 1')"
      ],
      "metadata": {
        "id": "be1mb7sDCc2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'topic_distribution')"
      ],
      "metadata": {
        "id": "nAOPnAZrCc6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(lda)"
      ],
      "metadata": {
        "id": "c_-Rcxm8Cc-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_model(lda, plot = 'umap')"
      ],
      "metadata": {
        "id": "HkDJI0a_CdCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo 2 Automl**"
      ],
      "metadata": {
        "id": "bsWdeMgICohF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando os 5 primeiros dados\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "XvB6iICqDK4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando os 5 últimos dados\n",
        "data.tail(5)"
      ],
      "metadata": {
        "id": "leJ7vzBrDK-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando linhas e colunas\n",
        "data.shape"
      ],
      "metadata": {
        "id": "G7wpR5cpDLB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informações dos dados\n",
        "data.info()"
      ],
      "metadata": {
        "id": "lgrVomuSDLFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tipo dados\n",
        "data.dtypes"
      ],
      "metadata": {
        "id": "mH2R41BUDLJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Amostra simples 5 \n",
        "data.sample(5)"
      ],
      "metadata": {
        "id": "VHjiKytUDLNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colunas númericas\n",
        "nub = [\"score\", \n",
        "       \"num_comments\",\n",
        "       \"created\", \n",
        "       \"created\"]\n",
        "\n",
        "# Coluna categorica\n",
        "cat = [\"title\", \n",
        "       \"subreddit\", \n",
        "       \"url\", \n",
        "       \"num_comments\"]\n",
        "\n",
        "# Coluna target\n",
        "target = [\"body\"]"
      ],
      "metadata": {
        "id": "zpXK4bzDDwAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['body'] = data['body'].astype(str)\n",
        "data['title'] = data['title'].astype(str)"
      ],
      "metadata": {
        "id": "UGb7WsyUEU1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total body\n",
        "data[\"body\"].value_counts()"
      ],
      "metadata": {
        "id": "8OYJ5ZcCDwFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "todos_palavras = ' '.join([texto for texto in data[\"body\"]])\n",
        "nuvem_palavras = WordCloud(width = 800, \n",
        "                           height = 500, \n",
        "                           max_font_size = 110,\n",
        "                           collocations = False).generate(todos_palavras)\n",
        "\n",
        "plt.figure(figsize= (25.5, 17))\n",
        "plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "40LKkYE_DwIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "todos_palavras = ' '.join([texto for texto in data[\"title\"]])\n",
        "nuvem_palavras = WordCloud(width = 800, \n",
        "                           height = 500, \n",
        "                           max_font_size = 110,\n",
        "                           collocations = False).generate(todos_palavras)\n",
        "\n",
        "plt.figure(figsize= (25.5, 17))\n",
        "plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "75qiwAYsELhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pré-processamento**"
      ],
      "metadata": {
        "id": "YJHsv87GExpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas sistema\n",
        "import re\n",
        "import unicodedata\n",
        "import itertools\n",
        "\n",
        "# Importando NLTK NLP\n",
        "# Baixando pacote do nltk\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Baixando todos os complementos NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "csxAIdcoELoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mundando os tipo de dados de object para string \n",
        "data['body'] = data['body'].astype(str)\n",
        "data['title'] = data['title'].astype(str)"
      ],
      "metadata": {
        "id": "9yg-CMr0E122"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "NcWRW8lqE19_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Dados de limpeza para modelo PLN\n",
        "# Variável para treino\n",
        "x = data[\"body\"]\n",
        "\n",
        "# Lista de stopwords\n",
        "list_stop_words = ['covfefe']\n",
        "\n",
        "# Recebe uma lista de palavras ou texto como entrada e retorna um conjunto de palavras mais limpo. \n",
        "# A função faz normalização, codificação/decodificação, letras minúsculas e lematização.\n",
        "def limpeza(texto):\n",
        "    WNL = nltk.stem.WordNetLemmatizer()\n",
        "    stop_words2 = nltk.corpus.stopwords.words(\"english\") + stopwords\n",
        "    texto = (unicodedata.normalize(\"NFKD\", texto).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\").lower())\n",
        "    WORDS = re.sub(r'[^\\w\\s]', '', texto).split()\n",
        "    return [WNL.lemmatize(word) for word in WORDS if word not in stop_words2]\n",
        "\n",
        "# Remove stop words: Removendo as stop words na base de dados\n",
        "def remove_stop_words(instancia): # Removendo as stop words\n",
        "    stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
        "    return (\" \".join(palavras))\n",
        "\n",
        "# Palavras derivacionalmente relacionadas com significados semelhantes, palavras para retornar documentos que contenham outra palavra no conjunto.\n",
        "def text_stemming(instancia):\n",
        "    stemmer = nltk.stem.RSLPStemmer()\n",
        "    palavras = []\n",
        "    for w in instancia.split():\n",
        "        palavras.append(stemmer.stem(w))\n",
        "        return (\" \".join(palavras))\n",
        "\n",
        "# Limpeza na base de dados limpando dados de web com http e outros.\n",
        "def dados_limpos(instancia): \n",
        "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
        "    return (instancia)\n",
        "\n",
        "#Lemmatization: Em linguística é o processo de agrupar as formas flexionadas de uma palavra para que possam ser analisadas como um único item, identificado pelo lema da palavra , ou forma de dicionário.\n",
        "def Lemmatization(instancia):\n",
        "    palavras = []\n",
        "    for w in instancia.split():\n",
        "        palavras.append(wordnet_lemmatizer.lemmatize(w))\n",
        "        return (\" \".join(palavras))\n",
        "\n",
        "# Preprocessing: Pré - processamento da base de dados que serão ser para análise de dados.\n",
        "def Preprocessing(instancia):\n",
        "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','')\n",
        "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
        "    return (\" \".join(palavras))\n",
        "\n",
        "# remover caracteres alphanuméricos\n",
        "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', '', x)\n",
        "\n",
        "# remover pontuações\n",
        "punc = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
        "\n",
        "# remover espaços duplos\n",
        "remove_space = lambda x: x.replace('  ', ' ')\n",
        "\n",
        "# Removendo pontuações descrições itens com expressão regular\n",
        "data['body'] = data['body'].str.replace('[,.:;!?]+', ' ', regex=True).copy()\n",
        "\n",
        "# Removendo os caracteres especiais de descrições \n",
        "data['body'] = data['body'].str.replace ('[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', regex=True).copy()\n",
        "\n",
        "# Removendo palavras com números \n",
        "data['body'] = data['body'].str.replace('[0-9]+', '', regex=True).copy()\n",
        "\n",
        "# Gerando a base dados limpo\n",
        "x = [Preprocessing(i) for i in x]\n",
        "\n",
        "# Aplicando nova coluna\n",
        "data[\"text_clean\"] = data[\"body\"].apply(Preprocessing)\n",
        "\n",
        "# Mundando os tipo de dados de object para string \n",
        "data[\"text_clean\"] = data[\"text_clean\"].astype(str)\n",
        "\n",
        "# Salvando base textos\n",
        "# Salvando arquivo em csv\n",
        "data.to_csv(\"text_clean.csv\", index=False)\n",
        "\n",
        "# Salvando arquivo em text\n",
        "data.to_csv(\"text_clean.text\", index=False)"
      ],
      "metadata": {
        "id": "WgnsOq0NELst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G5TW9DDRFIzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.text_clean.head(15)"
      ],
      "metadata": {
        "id": "YvS9d-VVELwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "todos_palavras = ' '.join([texto for texto in data[\"text_clean\"]])\n",
        "nuvem_palavras = WordCloud(width = 800, \n",
        "                           height = 500, \n",
        "                           max_font_size = 110,\n",
        "                           collocations = False).generate(todos_palavras)\n",
        "\n",
        "plt.figure(figsize= (25.5, 17))\n",
        "plt.title(\"Nuvem de palavras limpas\")\n",
        "plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5F6O914xDwLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo nlp - Pré treinado spacy\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "H4xhS6dqDwOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo Automl 2**"
      ],
      "metadata": {
        "id": "RQsvcGqGFQnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.nlp import *\n",
        "\n",
        "model = setup(data = data, \n",
        "                   target = 'text_clean', \n",
        "                   session_id = 123)"
      ],
      "metadata": {
        "id": "yrJzlPcFCdGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda2 = create_model('lda')\n",
        "lda2"
      ],
      "metadata": {
        "id": "oUDi2UrUCr6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = assign_model(lda2)\n",
        "df2.head(15)"
      ],
      "metadata": {
        "id": "AyBqS3OICr9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model()"
      ],
      "metadata": {
        "id": "vh0kxIuYC5c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda2, plot = 'frequency')"
      ],
      "metadata": {
        "id": "BooU0I4LFm09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda2, plot = 'topic_distribution')"
      ],
      "metadata": {
        "id": "mFFgVrHuFm5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda2, plot = 'topic_model')"
      ],
      "metadata": {
        "id": "pvmgi4pMFm8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(plot = 'bigram')"
      ],
      "metadata": {
        "id": "lLxa0CU4Fm_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda2, plot = 'frequency', topic_num = 'Topic 1')"
      ],
      "metadata": {
        "id": "1JJu1VroGV2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda2, plot = 'frequency', topic_num = 'Topic 2')"
      ],
      "metadata": {
        "id": "0597qRLjFtva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda2, plot = 'topic_distribution')"
      ],
      "metadata": {
        "id": "Hsgo5OCyFtzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(lda2)"
      ],
      "metadata": {
        "id": "6CXzhmVcFt2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_unsupervised = tune_model(model = 'lda2', \n",
        "                                multi_core = True)"
      ],
      "metadata": {
        "id": "PuexxYMhFt5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(lda,'Final LDA Model 08Feb2020')"
      ],
      "metadata": {
        "id": "17Sl-nIUFt8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_lda = load_model('Final LDA Model 08Feb2020')\n",
        "print(saved_lda)"
      ],
      "metadata": {
        "id": "hCUVoPjIFt_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pUC6vLAsF8b7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}